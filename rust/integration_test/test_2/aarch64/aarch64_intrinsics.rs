// x86平台下实现
#[cfg(all(any(target_arch = "aarch64"), target_feature = "neon"))]
fn add()
{
    use std::arch::aarch64::*;
    unsafe {
        __breakpoint();
        __crc32b();
        __crc32h();
        __crc32w();
        __crc32d();
        __crc32cb();
        __crc32ch();
        __crc32cw();
        __crc32cd();
        __dmb();
        __dsb();
        __isb();
        __nop();
        __rsr();
        __rsrp();
        __wsr();
        __wsrp();
        _cls_u32();
        _cls_u64();
        _clz_u64();
        _rbit_u64();
        _rev_u16();
        _rev_u32();
        _rev_u64();
        brk();
        vadd_f32();
        vadd_f64();
        vadd_s8();
        vadd_s16();
        vadd_s32();
        vadd_u8();
        vadd_u16();
        vadd_u32();
        vaddd_s64();
        vaddd_u64();
        vaddl_s8();
        vaddl_s16();
        vaddl_s32();
        vaddl_u8();
        vaddl_u16();
        vaddl_u32();
        vaddq_f32();
        vaddq_f64();
        vaddq_s8();
        vaddq_s16();
        vaddq_s32();
        vaddq_s64();
        vaddq_u8();
        vaddq_u16();
        vaddq_u32();
        vaddq_u64();
        vaesdq_u8();
        vaeseq_u8();
        vaesimcq_u8();
        vaesmcq_u8();
        vcombine_f32();
        vcombine_f64();
        vcombine_p8();
        vcombine_p16();
        vcombine_p64();
        vcombine_s8();
        vcombine_s16();
        vcombine_s32();
        vcombine_s64();
        vcombine_u8();
        vcombine_u16();
        vcombine_u32();
        vcombine_u64();
        vmaxv_f32();
        vmaxv_s8();
        vmaxv_s16();
        vmaxv_s32();
        vmaxv_u8();
        vmaxv_u16();
        vmaxv_u32();
        vmaxvq_f32();
        vmaxvq_f64();
        vmaxvq_s8();
        vmaxvq_s16();
        vmaxvq_s32();
        vmaxvq_u8();
        vmaxvq_u16();
        vmaxvq_u32();
        vminv_f32();
        vminv_s8();
        vminv_s16();
        vminv_s32();
        vminv_u8();
        vminv_u16();
        vminv_u32();
        vminvq_f32();
        vminvq_f64();
        vminvq_s8();
        vminvq_s16();
        vminvq_s32();
        vminvq_u8();
        vminvq_u16();
        vminvq_u32();
        vmovl_s8();
        vmovl_s16();
        vmovl_s32();
        vmovl_u8();
        vmovl_u16();
        vmovl_u32();
        vmovn_s16();
        vmovn_s32();
        vmovn_s64();
        vmovn_u16();
        vmovn_u32();
        vmovn_u64();
        vpmax_f32();
        vpmax_s8();
        vpmax_s16();
        vpmax_s32();
        vpmax_u8();
        vpmax_u16();
        vpmax_u32();
        vpmaxq_f32();
        vpmaxq_f64();
        vpmaxq_s8();
        vpmaxq_s16();
        vpmaxq_s32();
        vpmaxq_u8();
        vpmaxq_u16();
        vpmaxq_u32();
        vpmin_f32();
        vpmin_s8();
        vpmin_s16();
        vpmin_s32();
        vpmin_u8();
        vpmin_u16();
        vpmin_u32();
        vpminq_f32();
        vpminq_f64();
        vpminq_s8();
        vpminq_s16();
        vpminq_s32();
        vpminq_u8();
        vpminq_u16();
        vpminq_u32();
        vqtbl1_p8();
        vqtbl1_s8();
        vqtbl1_u8();
        vqtbl1q_p8();
        vqtbl1q_s8();
        vqtbl1q_u8();
        vqtbl2_p8();
        vqtbl2_s8();
        vqtbl2_u8();
        vqtbl2q_p8();
        vqtbl2q_s8();
        vqtbl2q_u8();
        vqtbl3_p8();
        vqtbl3_s8();
        vqtbl3_u8();
        vqtbl3q_p8();
        vqtbl3q_s8();
        vqtbl3q_u8();
        vqtbl4_p8();
        vqtbl4_s8();
        vqtbl4_u8();
        vqtbl4q_p8();
        vqtbl4q_s8();
        vqtbl4q_u8();
        vqtbx1_p8();
        vqtbx1_s8();
        vqtbx1_u8();
        vqtbx1q_p8();
        vqtbx1q_s8();
        vqtbx1q_u8();
        vqtbx2_p8();
        vqtbx2_s8();
        vqtbx2_u8();
        vqtbx2q_p8();
        vqtbx2q_s8();
        vqtbx2q_u8();
        vqtbx3_p8();
        vqtbx3_s8();
        vqtbx3_u8();
        vqtbx3q_p8();
        vqtbx3q_s8();
        vqtbx3q_u8();
        vqtbx4_p8();
        vqtbx4_s8();
        vqtbx4_u8();
        vqtbx4q_p8();
        vqtbx4q_s8();
        vqtbx4q_u8();
        vrsqrte_f32();
        vsha1cq_u32();
        vsha1h_u32();
        vsha1mq_u32();
        vsha1pq_u32();
        vsha1su0q_u32();
        vsha1su1q_u32();
        vsha256h2q_u32();
        vsha256hq_u32();
        vsha256su0q_u32();
        vsha256su1q_u32();
        vtbl1_p8();
        vtbl1_s8();
        vtbl1_u8();
        vtbl2_p8();
        vtbl2_s8();
        vtbl2_u8();
        vtbl3_p8();
        vtbl3_s8();
        vtbl3_u8();
        vtbl4_p8();
        vtbl4_s8();
        vtbl4_u8();
        vtbx1_p8();
        vtbx1_s8();
        vtbx1_u8();
        vtbx2_p8();
        vtbx2_s8();
        vtbx2_u8();
        vtbx3_p8();
        vtbx3_s8();
        vtbx3_u8();
        vtbx4_p8();
        vtbx4_s8();
        vtbx4_u8();
    }
}





